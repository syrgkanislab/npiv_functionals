{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Magic functinos\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import mean_ci\n",
    "from mliv.neuralnet import AGMMEarlyStop as AGMM\n",
    "from mliv.neuralnet.moments import avg_small_diff\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_2$-Regularized AGMM with Neural Net Test Function\n",
    "\n",
    "We solve the problem:\n",
    "\\begin{equation}\n",
    "\\min_{\\theta} \\max_{w} \\frac{1}{n} \\sum_i (y_i - h_{\\theta}(x_i)) f_w(z_i) - f_w(z_i)^2\n",
    "\\end{equation}\n",
    "where $h_{\\theta}$ and $f_w$ are two neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(it, n, n_z, n_t, iv_strength, fname, dgp_num, moment_fn):\n",
    "    np.random.seed(it)\n",
    "    \n",
    "    #####\n",
    "    # Neural network parameters\n",
    "    ####\n",
    "    p = 0.1 # dropout prob of dropout layers throughout notebook\n",
    "    n_hidden = 100 # width of hidden layers throughout notebook\n",
    "\n",
    "    learner = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "                            #nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "                            nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "    # For any method that uses an unstructured adversary test function f(z)\n",
    "    adversary_fn = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                                 #nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "                                 nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "    learner_lr = 1e-4\n",
    "    adversary_lr = 1e-4\n",
    "    learner_l2 = 1e-3\n",
    "    adversary_l2 = 1e-3\n",
    "    n_epochs = 200\n",
    "    bs = 100\n",
    "    burn_in = 100\n",
    "    device = None\n",
    "    \n",
    "    ######\n",
    "    # Train test split\n",
    "    ######\n",
    "    Z, T, Y, true_fn = get_data(n, n_z, iv_strength, get_tau_fn(fn_dict[fname]), dgp_num)\n",
    "    Z_train, Z_val, T_train, T_val, Y_train, Y_val = train_test_split(Z, T, Y, test_size=.5, shuffle=True)\n",
    "    Z_train, T_train, Y_train = map(lambda x: torch.Tensor(x), (Z_train, T_train, Y_train))\n",
    "    Z_val, T_val, Y_val = map(lambda x: torch.Tensor(x).to(device), (Z_val, T_val, Y_val))\n",
    "\n",
    "    \n",
    "    #####\n",
    "    # Train IV function and \"riesz\" representer xi\n",
    "    #####\n",
    "    np.random.seed(12356)\n",
    "    agmm = AGMM(learner, adversary_fn).fit(Z_train, T_train, Y_train, Z_val, T_val, Y_val,\n",
    "                                           learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                                           learner_l2=learner_l2, adversary_l2=adversary_l2,\n",
    "                                           n_epochs=n_epochs, bs=bs, logger=None,\n",
    "                                           model_dir=f'agmm_model_{it}', device=device)\n",
    "\n",
    "    reisz = AGMM(learner, adversary_fn).fit(Z_train, T_train, Y_train, Z_val, T_val, Y_val,\n",
    "                                            learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                                            learner_l2=learner_l2, adversary_l2=adversary_l2,\n",
    "                                            n_epochs=n_epochs, bs=bs, logger=None,\n",
    "                                            model_dir=f'riesz_model_{it}', device=device,\n",
    "                                            riesz=True, moment_fn=moment_fn)\n",
    "\n",
    "    qfun = RandomForestRegressor(min_samples_leaf=20).fit(Z_train, reisz.predict(T_train))\n",
    "    qfun_avg = RandomForestRegressor(min_samples_leaf=20).fit(Z_train,\n",
    "                                                              reisz.predict(T_train, model='avg', burn_in=burn_in))\n",
    "    \n",
    "    #####\n",
    "    # Average moment calculation\n",
    "    #####\n",
    "    direct = moment_fn(T_val, agmm.predict, device='cpu').flatten()\n",
    "    residual = (Y_val - agmm.predict(T_val)).detach().numpy().flatten()\n",
    "    qvalues = qfun.predict(Z_val).flatten()\n",
    "    pseudo = direct + qvalues * residual\n",
    "    dr = mean_ci(pseudo)\n",
    "    ipw = mean_ci(qvalues * Y_val.detach().numpy().flatten())\n",
    "    reg = mean_ci(direct)\n",
    "    \n",
    "    xivalues = reisz.predict(T_val).flatten()\n",
    "    coef = np.mean(qvalues * residual) / np.mean(qvalues * xivalues)\n",
    "    pseudo_tmle = direct + coef * moment_fn(T_val, reisz.predict, device='cpu').flatten()\n",
    "    pseudo_tmle += qvalues * (residual - coef * xivalues)\n",
    "    tmle = mean_ci(pseudo_tmle)\n",
    "    \n",
    "    direct_avg = moment_fn(T_val,\n",
    "                           lambda x: agmm.predict(x, model='avg', burn_in=burn_in), device='cpu').flatten()\n",
    "    residual_avg = (Y_val - agmm.predict(T_val, model='avg', burn_in=burn_in)).detach().numpy().flatten()\n",
    "    qvalues_avg = qfun_avg.predict(Z_val).flatten()\n",
    "    pseudo_avg = direct_avg + qvalues_avg * residual_avg\n",
    "    dr_avg = mean_ci(pseudo_avg)\n",
    "    ipw_avg = mean_ci(qvalues_avg * Y_val.detach().numpy().flatten())\n",
    "    reg_avg = mean_ci(direct_avg)\n",
    "\n",
    "    xivalues_avg = reisz.predict(T_val, model='avg', burn_in=burn_in).flatten()\n",
    "    coef_avg = np.mean(qvalues_avg * residual_avg) / np.mean(qvalues_avg * xivalues_avg)\n",
    "    pseudo_tmle_avg = (direct_avg \n",
    "                       + coef_avg * moment_fn(T_val, lambda x: reisz.predict(x, model='avg', burn_in=burn_in),\n",
    "                                              device='cpu').flatten())\n",
    "    pseudo_tmle_avg += qvalues_avg * (residual_avg - coef_avg * xivalues_avg)\n",
    "    tmle_avg = mean_ci(pseudo_tmle_avg)\n",
    "\n",
    "    return dr, tmle, ipw, reg, dr_avg, tmle_avg, ipw_avg, reg_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 0.1904\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "n_z = 1\n",
    "n_t = 1\n",
    "iv_strength = .7\n",
    "fname = 'sigmoid'\n",
    "dgp_num = 5\n",
    "epsilon = 0.1 # average finite difference epsilon\n",
    "moment_fn = lambda x, fn, device: avg_small_diff(x, fn, device, epsilon)\n",
    "\n",
    "Z, T, Y, true_fn = get_data(1000000, n_z, iv_strength, get_tau_fn(fn_dict[fname]), dgp_num)\n",
    "true = np.mean(moment_fn(T, true_fn, device='cpu'))\n",
    "print(f'True: {true:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp(1, n, n_z, n_t, iv_strength, fname, dgp_num, moment_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "n_z = 1\n",
    "n_t = 1\n",
    "dgp_num = 5\n",
    "epsilon = 0.1 # average finite difference epsilon\n",
    "moment_fn = lambda x, fn, device: avg_small_diff(x, fn, device, epsilon)\n",
    "\n",
    "for fname in ['abs', '2dpoly', 'sigmoid', 'sin', '3dpoly', 'abspos']:\n",
    "    for n in [1000, 2000]:\n",
    "        for iv_strength in [.5, .7, .9]:\n",
    "            Z, T, Y, true_fn = get_data(1000000, n_z, iv_strength, get_tau_fn(fn_dict[fname]), dgp_num)\n",
    "            true = np.mean(moment_fn(T, true_fn, device='cpu'))\n",
    "            print(f'True: {true:.4f}')\n",
    "            results = Parallel(n_jobs=-1, verbose=3)(delayed(exp)(it, n, n_z, n_t, iv_strength,\n",
    "                                                                  fname, dgp_num, moment_fn)\n",
    "                                                     for it in range(100))\n",
    "            joblib.dump((true, results), f'res_fn_{fname}_n_{n}_stregth_{iv_strength}_eps_{epsilon}.jbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(fname, n, iv_strength, dr, tmle, ipw, direct, true):\n",
    "    plt.title(f'fname={fname}, n={n}, strength={iv_strength}, true={true:.3f}\\n'\n",
    "              f'dr: Cov={np.mean((dr[:, 1] <= true) & (true <= dr[:, 2])):.3f}, '\n",
    "              f'rmse={np.sqrt(np.mean((dr[:, 0]-true)**2)):.3f}, '\n",
    "              f'bias={np.mean((dr[:, 0]-true)):.3f}\\n'\n",
    "              f'tmle: Cov={np.mean((tmle[:, 1] <= true) & (true <= tmle[:, 2])):.3f}, '\n",
    "              f'rmse={np.sqrt(np.mean((tmle[:, 0]-true)**2)):.3f}, '\n",
    "              f'bias={np.mean((tmle[:, 0]-true)):.3f}\\n'\n",
    "              f'ipw: Cov={np.mean((ipw[:, 1] <= true) & (true <= ipw[:, 2])):.3f}, '\n",
    "              f'rmse={np.sqrt(np.mean((ipw[:, 0]-true)**2)):.3f}, '\n",
    "              f'bias={np.mean((ipw[:, 0]-true)):.3f}\\n'\n",
    "              f'direct: Cov={np.mean((direct[:, 1] <= true) & (true <= direct[:, 2])):.3f}, '\n",
    "              f'rmse={np.sqrt(np.mean((direct[:, 0]-true)**2)):.3f}, '\n",
    "              f'bias={np.mean((direct[:, 0]-true)):.3f}\\n')\n",
    "    plt.hist(dr[:, 0], label='dr')\n",
    "    plt.hist(tmle[:, 0], label='tmle', alpha=.4)\n",
    "    plt.hist(ipw[:, 0], label='ipw', alpha=.4)\n",
    "    plt.hist(direct[:, 0], label='direct', alpha=.4)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from early stopping models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "it = 1\n",
    "for fname in ['abs', '2dpoly', 'sigmoid', 'sin', '3dpoly', 'abspos']:\n",
    "    for n in [1000, 2000]:\n",
    "        for iv_strength in [.5, .7, .9]:\n",
    "            plt.subplot(3, 3, it)\n",
    "            true, results = joblib.load(f'res_fn_{fname}_n_{n}_stregth_{iv_strength}_eps_{epsilon}.jbl')\n",
    "            dr = np.array([r[0] for r in results])\n",
    "            tmle = np.array([r[1] for r in results])\n",
    "            ipw = np.array([r[2] for r in results])\n",
    "            direct = np.array([r[3] for r in results])\n",
    "            plot_results(fname, n, iv_strength, dr, tmle, ipw, direct, true)\n",
    "            it += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from avg models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "it = 1\n",
    "for fname in ['abs', '2dpoly', 'sigmoid', 'sin', '3dpoly', 'abspos']:\n",
    "    for n in [1000, 2000]:\n",
    "        for iv_strength in [.5, .7, .9]:\n",
    "            plt.subplot(3, 3, it)\n",
    "            true, results = joblib.load(f'res_fn_{fname}_n_{n}_stregth_{iv_strength}_eps_{epsilon}.jbl')\n",
    "            dr = np.array([r[4] for r in results])\n",
    "            tmle = np.array([r[5] for r in results])\n",
    "            ipw = np.array([r[6] for r in results])\n",
    "            direct = np.array([r[7] for r in results])\n",
    "            plot_results(fname, n, iv_strength, dr, tmle, ipw, direct, true)\n",
    "            it += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNetExamples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
